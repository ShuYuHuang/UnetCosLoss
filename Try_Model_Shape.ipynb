{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f4f6fcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "def cosine(fts, prototype, scaler=1):\n",
    "    cos=torch.stack([F.cosine_similarity(fts, p[None,..., None, None], dim=1) * scaler\n",
    "        for p in prototype],dim=1)\n",
    "    return cos\n",
    "class MetricLayer(nn.Module):\n",
    "    def __init__(self, n_in_features,n_out_features=10,metric=cosine):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.Tensor(n_out_features, n_in_features))\n",
    "        nn.init.xavier_uniform_(self.weight,gain=1.0)\n",
    "        self.metric=metric\n",
    "    def forward(self,x):\n",
    "        return self.metric(x,self.weight)\n",
    "class SegModel(nn.Module):\n",
    "    def __init__(self,backbone,head):\n",
    "        super().__init__()\n",
    "        assert(backbone is not None)\n",
    "        self.backbone=backbone\n",
    "        self.head=head\n",
    "    def forward(self,data,label=None):\n",
    "        # Transfer Learing: backbone+ output head\n",
    "        hidden=self.backbone(data)\n",
    "        logits=self.head(hidden)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "132daea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.unet import UNet\n",
    "WAYS=3\n",
    "CH=3\n",
    "LATENT_DIM=128\n",
    "g=UNet(input_chs=CH)\n",
    "head=MetricLayer(LATENT_DIM,n_out_features=WAYS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ebe2e1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=SegModel(g,head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cff79818",
   "metadata": {},
   "outputs": [],
   "source": [
    "l=model(torch.ones((4,3,128,128)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d7564e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2, eps=1e-10):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        self.eps = torch.tensor(eps,dtype=torch.float32)\n",
    "        self.ce = nn.CrossEntropyLoss()\n",
    "    def forward(self,  y_pred,y_true):\n",
    "        # 計算cross entropy\n",
    "        logp = self.ce(y_pred+self.eps, y_true)\n",
    "        # 計算乘上gamma次方後的entropy反方機率(將對比放大)\n",
    "        p = torch.exp(-logp)\n",
    "        loss = (1 - p) ** self.gamma * logp\n",
    "        return loss.mean()\n",
    "\n",
    "class AddMarginLoss(nn.Module):\n",
    "    def __init__(self,ways, s=15.0, m=0.40,loss_fn=FocalLoss()):\n",
    "        super().__init__()\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.loss_fn=loss_fn\n",
    "        self.ways=ways\n",
    "    def forward(self, cosine, label=None):\n",
    "        # 扣掉對cosine的margin\n",
    "        cos_phi = cosine - self.m\n",
    "        # 將onehot沒選中的類別不套用margin，onehot選中的套用margin     \n",
    "        one_hot=F.one_hot(label,self.ways).transpose(-1,-2).transpose(-2,1).to(torch.float32)\n",
    "        metric = (one_hot * cos_phi) + ((1.0 - one_hot) * cosine)\n",
    "        # 將輸出對比放大\n",
    "        metric *= self.s\n",
    "        return self.loss_fn(metric,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "3a1335b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn=AddMarginLoss(ways=3,s=3.0, m=0.40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d555dab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.7329, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(l,torch.ones((4,64,64),dtype=int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ff880f65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 128, 128])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.one_hot(torch.ones((4,128,128),dtype=int),3).transpose(-1,-2).transpose(-2,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7dfc8579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 64, 64])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e60c15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
